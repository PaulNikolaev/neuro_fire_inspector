import os
import re
from typing import Dict
from pypdf import PdfReader
from pdf2image import convert_from_path
import pytesseract
from langchain_core.documents import Document


def extract_text_from_scanned_pdf(path: str, lang: str = "rus") -> str:
    """
    –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –æ—Ç—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ PDF —Å –ø–æ–º–æ—â—å—é OCR.
    """
    text = ""
    try:
        pages = convert_from_path(path)
        for i, page in enumerate(pages):
            page_text = pytesseract.image_to_string(page, lang=lang)
            text += f"\n--- Page {i + 1} ---\n{page_text}"
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ OCR –¥–ª—è {os.path.basename(path)}: {e}")
    return text.strip()


def extract_text_from_pdf(path: str, min_length: int = 100) -> str:
    """
    –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF. –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π, –ø—Ä–∏–º–µ–Ω—è–µ–º OCR.
    """
    text = ""
    try:
        reader = PdfReader(path)
        for page in reader.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text + "\n"
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è PDF {os.path.basename(path)}: {e}")

    # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ —Å—Ç—Ä–æ–∫ –ø–æ–¥ Windows
    text = text.replace("\r\n", "\n").replace("\r", "\n")

    # –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ –º–∞–ª–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º OCR
    if len(text.strip()) < min_length:
        print(f"üîç –ò—Å–ø–æ–ª—å–∑—É–µ–º OCR –¥–ª—è {os.path.basename(path)}")
        text = extract_text_from_scanned_pdf(path)

    # —É–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    return re.sub(r"\s{2,}", " ", text).strip()


def parse_articles(text: str) -> Dict[str, str]:
    """
    –†–∞–∑–±–æ—Ä —Ç–µ–∫—Å—Ç–∞ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–≥–æ –∞–∫—Ç–∞ –Ω–∞ —Å—Ç–∞—Ç—å–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å: {–Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏: —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏}
    """
    # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ —Å—Ç—Ä–æ–∫
    text = text.replace("\r\n", "\n").replace("\r", "\n")

    articles = {}
    # –ø–∞—Ç—Ç–µ—Ä–Ω –∏—â–µ—Ç "–°—Ç–∞—Ç—å—è N" –∏–ª–∏ "–°—Ç–∞—Ç—å—è N.M" –∏ —Ç–µ–∫—Å—Ç –¥–æ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç–∞—Ç—å–∏
    pattern = re.compile(r"(–°—Ç–∞—Ç—å—è\s+\d+[\.\d]*)(.*?)(?=–°—Ç–∞—Ç—å—è\s+\d+|\Z)", re.DOTALL)
    for article, content in pattern.findall(text):
        articles[article.strip()] = content.strip()
    return articles


def load_documents_from_pdf_dir(pdf_dir: str) -> list[Document]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ PDF –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, –ø–∞—Ä—Å–∏—Ç —Å—Ç–∞—Ç—å–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ Document.
    """
    structured_documents = []
    for filename in os.listdir(pdf_dir):
        if not filename.lower().endswith(".pdf"):
            continue

        path = os.path.join(pdf_dir, filename)
        print(f"üìò –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {filename}")
        text = extract_text_from_pdf(path)
        if not text:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ {filename}")
            continue

        articles = parse_articles(text)
        for article, content in articles.items():
            structured_documents.append(
                Document(
                    page_content=content,
                    metadata={"source": filename, "article": article}
                )
            )

    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(structured_documents)} —Å—Ç–∞—Ç–µ–π –∏–∑ {pdf_dir}")
    return structured_documents
